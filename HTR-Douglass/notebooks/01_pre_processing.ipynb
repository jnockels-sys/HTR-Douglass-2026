{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a23ffe4-05ab-4acb-ac90-0d4ef75fe84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3fcc74-43af-4a45-b011-88d7caa64a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/joenockels/douglass-kg/notebooks')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba0a2ee-da8c-4701-a6d3-f0e55465b1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw text: 41624 characters\n",
      "SHA256 checksum: f627b8559d8066503236268348a34f048b605cee7e63c577fd9dd0aee33cfae6\n",
      "Cleaned text length: 41623\n",
      "Clean working copy saved at /Users/joenockels/douglass-kg/data/processed/HP_clean.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "# -----------------------------\n",
    "# Define paths\n",
    "# -----------------------------\n",
    "PROJECT_ROOT = Path.cwd().parent  # <-- move up from notebooks\n",
    "RAW_PATH = PROJECT_ROOT / \"data\" / \"raw\" / \"HP.txt\"\n",
    "PROCESSED_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"HP_clean.txt\"\n",
    "\n",
    "# -----------------------------\n",
    "# Function to compute SHA256 checksum\n",
    "# -----------------------------\n",
    "def file_checksum(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        h.update(f.read())\n",
    "    return h.hexdigest()\n",
    "\n",
    "# -----------------------------\n",
    "# Load raw text\n",
    "# -----------------------------\n",
    "with open(RAW_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(f\"Loaded raw text: {len(raw_text)} characters\")\n",
    "print(\"SHA256 checksum:\", file_checksum(RAW_PATH))\n",
    "\n",
    "# -----------------------------\n",
    "# Light normalization (non-destructive)\n",
    "# -----------------------------\n",
    "clean_text = raw_text.replace(\"\\r\\n\", \"\\n\").strip()\n",
    "print(\"Cleaned text length:\", len(clean_text))\n",
    "\n",
    "# -----------------------------\n",
    "# Save cleaned working copy\n",
    "# -----------------------------\n",
    "PROCESSED_PATH.parent.mkdir(parents=True, exist_ok=True)  # Make sure folder exists\n",
    "with open(PROCESSED_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(clean_text)\n",
    "\n",
    "print(f\"Clean working copy saved at {PROCESSED_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e8a36c-6ad9-4aa9-923d-64aeb37dadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to separate HP entries based on dates, making a time_aware backdrop to the knowledge graph\n",
    "\n",
    "import re\n",
    "\n",
    "date_pattern = r'''\n",
    "^(\n",
    "    # 1ï¸âƒ£ Full date: 14 September 1886\n",
    "    \\d{1,2}\\s+\n",
    "    (January|February|March|April|May|June|July|August|September|October|November|December)\n",
    "    (?:\\s+\\d{4})?\n",
    "\n",
    "    |\n",
    "\n",
    "    # 2ï¸âƒ£ Weekday, 16\n",
    "    (Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday),\n",
    "    \\s*\\d{1,2}\n",
    "\n",
    "    |\n",
    "\n",
    "    # 3ï¸âƒ£ 18 September (no year)\n",
    "    \\d{1,2}\\s+\n",
    "    (January|February|March|April|May|June|July|August|September|October|November|December)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca21fb-5b2d-46a1-a298-102e5563ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to separate DD entries based on dates, making a time_aware backdrop to the knowledge graph\n",
    "\n",
    "import re\n",
    "\n",
    "# Pattern explanation:\n",
    "# (Jan|Feb|...|Dec) - matches abbreviated month names\n",
    "# :? - optional colon\n",
    "# \\s* - optional whitespace\n",
    "# \\d{1,2} - one or two digits for day\n",
    "# \\.? - optional period at end\n",
    "date_pattern = r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sept|Oct|Nov|Dec):?\\s*\\d{1,2}\\.?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec69386-404c-42ca-943b-5ed052fb8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split HP based on date_pattern\n",
    "\n",
    "matches = list(re.finditer(\n",
    "    date_pattern,\n",
    "    clean_text,\n",
    "    flags=re.MULTILINE | re.VERBOSE | re.IGNORECASE\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91394b76-8c6d-4c31-807a-256bcd22b6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 date headers\n",
      "First 5 dates: []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dates)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m date headers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFirst 5 dates:\u001b[39m\u001b[33m\"\u001b[39m, dates[:\u001b[32m5\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFirst entry snippet:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mentries\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[32m200\u001b[39m])  \u001b[38;5;66;03m# entries[0] may be preamble text\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# split DD based on date_pattern\n",
    "\n",
    "entries = re.split(date_pattern, clean_text)\n",
    "\n",
    "# Find all matched dates to keep as metadata\n",
    "dates = re.findall(date_pattern, clean_text)\n",
    "\n",
    "print(f\"Found {len(dates)} date headers\")\n",
    "print(\"First 5 dates:\", dates[:5])\n",
    "print(\"First entry snippet:\", entries[1][:200])  # entries[0] may be preamble text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46d4d11f-70f5-4c34-b553-e88d61ebfc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First structured entry:\n",
      "{'date': '14 September 1886', 'text': 'City of Rome.\\nDrove to the pier in a hansom, from Grand Central Hotel, at 1 oâ€™clock, a\\nbeautiful day, and after looking up our luggage went on board, and remained there,\\nlooking over the ship, watching the loading of the vessel and visiting with friends. In the\\nevening Frederick went on deck, but I was tired and undressed and mounted my perch,\\nthe upper berth, and though we had pulled close on the dock and were all night receiving\\nand loading freight just outside our port hole, I slept all night. As I said we went on board\\nearly, eager to see our room. We found it a very comfortable little place, the space\\nopposite the berths and under the window a port hole, a round eye of glass, is occupied\\nby the couch. Over it and over each berth is a wall pocket and over the stationary wash\\nbowl, between it and the mirror a fresh linen pocket for brushes, fresh water bottle,\\npneumatic bell call, and altogether a nice cosy little place. Dr Frauenstein called the\\nevening before sailing and we had a pleasant visit with him in the little boudoir\\nupholstered in old gold plush and Ebony. We talked of Miss Assing, & as the genial Dr\\nleft he threw his arms around Frederickâ€™s neck in a good old fashioned hug & kissed him,\\nkissed me, and ran off the steamer. A cordial wave of his hat from the dock and he was\\ngone.\\nBut all on board was the bustle of departure. On both ends of the long steamer a\\ncompany of stevedores was hoisting and lowering into the hold great loads of pressed\\ncotton for English manufacture, and as night came on a queer looking box boat steamed\\nalongside, and before morning emptied its contents, great quarters of iced beef, into the\\nhold of our ship. I descended from my perch, dressed, & was on deck before time to start.\\nThe Pilot, a pleasant calmed man of 45 yrs. passed a pleasant word with me before going\\ninto the pilot house. Frederick came up, and soon the whistle soundeds. he gang plank\\nwas pulled away and the mighty vessel moves quietly. These powerful tugs help to push\\nher enormous length around and as she gets rightly headed separate from her and go their\\nway. The pilot stays with us two or three hours, and leaves so quietly that we only know\\nit when he is gone. The Captain takes charge and we are fairly committed to the voyage.\\nThe ocean is as smooth as any river, and about 4 hours out takes on the dark, exceedingly\\ndark blue hue, that I have never before seen. For an hour or so it has an anxious mottled\\nappearance that for some time I study in vain, but finally conclude to be due to millions\\nof little waves or ripples receiving the sunlight at different angles. Only 71 passengers\\nlose themselves in the spaces of this mighty ship that one week ago landed at New York\\nhundreds of home returning travellers, and we are told that in London are many waiting\\npassage, as the books of all the steamers westward bound are filled till into November.\\nOne of the passengers is Rev. Henry Wayland son of old Dr. Wayland, and as Frederick\\nalready knew him it was pleasant to meet. He looks and appears as if he might himself\\ncommand a ship. He is totally without appearance of affectation, and hearty and plain in\\nhis manner of address, a six footer I am sure, and in a dark blue woolen suit including\\ncap. Frederick and he have already had some political conversation to which I was an\\ninterested listener. To me there was the smell of mugwumpery on his mental garments,\\nbut it might have been ship smell. Mr. Brelock too, who with his little daughter are\\npassengers, Frederick knew as a boy. He is a very pleasant man also. Just before coming\\ndown to the writing table in the pretty dining saloon, furnished in dark green, we got into\\nconversation with a young Englishman who has been making an 18 days visit to the\\nStates and Canada.\\nThe sea has been very smooth so far with but little rocking of the boats Night\\ncame on and we sought our berths. I slept well and was on deck at 5 1/2 oâ€™clock by N.Y.\\ntime. No one was there. The chairs had all been set in a cross passage and the decks\\nwashed down which is done during the night. Soon a cheery Englishman who with his\\nson a stout young man, spoke with us in the evening came on deck. Nearly opposite us at\\ntable sit Mr. and Mrs Chandler, she very pretty and gentle in appearance and he low in\\nvoice but with an air of quiet authority that commends him as a man not to be trifled\\nwith. The dining saloon is on the lowest floor I have seen, a large pleasant room in oak or\\nwhat looks like it, supported down its length by columns, the port holes or round\\nwindows looking out on either side of the ship upon the broad ocean, an organ in the\\nfarther End, to one side of which is the long writing table at which we, with others, write\\nand at which I am now sitting. This saloon is furnished in dark green plush, 8 long tables\\nExtending down the middle, with a row of short tables at either side. Part of one row of\\nshort tables and part of the long table next to it, only, are occupied, as we have so few\\npassengers. There is variety in the dishes and they are well selected and nicely prepared.\\nThe oat meal of breakfast is as good as anything we have, that is, it is to me a standby and\\ntastes good. Dr. Wayland sits way down at the end of the long table, and we are the last\\nof the inside away up the room. In the passage at the entrance of the dining room are the\\nstairs. Beyond in two narrow passages along the ship one Either side are state rooms, ours\\nbeing No 92, on right hand passage. Over the dining room is the drawing room, or saloon,\\nwith piano at further end, the middle occupied by an open space looking down into the\\ndining room, surrounded by a neat railing, and containing hanging plants and two\\ncanaries. Around the room are what would be settees, but that they are divided into\\nsections making of them individual chairs, the color of carpet and upholstery is greyish\\nand pleasing and restful to the Eye. Just outside this saloon are the decks where the\\nsteerage passengers are when they wish to be outside. Above this saloon again is a lovely\\nlittle boudoir in old gold plush and Ebony, and the deck on this floor is the promenade\\ndeck, where most of the cabin passengers spend much of their time.'}\n"
     ]
    }
   ],
   "source": [
    "# reassemble diary entries \n",
    "\n",
    "diary_entries = []\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    start = match.end()\n",
    "    end = matches[i + 1].start() if i + 1 < len(matches) else len(clean_text)\n",
    "\n",
    "    diary_entries.append({\n",
    "        \"date\": match.group(0).strip(),\n",
    "        \"text\": clean_text[start:end].strip()\n",
    "    })\n",
    "\n",
    "print(\"First structured entry:\")\n",
    "print(diary_entries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ed9134-ffd1-4aef-bdf1-17672b473d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert to a standardised timeset YYYY-MM-DDT00:00:00 format, needed for named entity recognition and the eventual KG in Gephi using timestamps\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def parse_diary_date(date_str, current_year, last_month=None):\n",
    "\n",
    "    original = date_str\n",
    "    clean = date_str.lower()\n",
    "    clean = re.sub(r'[.,:]', '', clean)\n",
    "    clean = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', clean)\n",
    "    clean = clean.strip()\n",
    "\n",
    "    parts = clean.split()\n",
    "\n",
    "    day = None\n",
    "    month = None\n",
    "    year = current_year\n",
    "\n",
    "    # Case 1: 14 September 1886\n",
    "    if len(parts) >= 2 and parts[0].isdigit() and parts[1] in month_map:\n",
    "        day = int(parts[0])\n",
    "        month = month_map[parts[1]]\n",
    "        if len(parts) == 3 and parts[2].isdigit():\n",
    "            year = int(parts[2])\n",
    "\n",
    "    # Case 2: 18 September\n",
    "    elif len(parts) == 2 and parts[0].isdigit() and parts[1] in month_map:\n",
    "        day = int(parts[0])\n",
    "        month = month_map[parts[1]]\n",
    "\n",
    "    # Case 3: Thursday 16\n",
    "    elif parts[0] in weekdays and len(parts) == 2 and parts[1].isdigit():\n",
    "        if last_month is None:\n",
    "            raise ValueError(f\"No month context for weekday entry: {original}\")\n",
    "        day = int(parts[1])\n",
    "        month = last_month\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognised date format: {original}\")\n",
    "\n",
    "    # Detect rollover ONLY if month explicitly changes\n",
    "    if last_month and month and month < last_month:\n",
    "        year += 1\n",
    "\n",
    "    # ðŸ”Ž Validate date safely\n",
    "    try:\n",
    "        dt = datetime(year, month, day)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            f\"Invalid date constructed from '{original}' â†’ \"\n",
    "            f\"year={year}, month={month}, day={day}\"\n",
    "        ) from e\n",
    "\n",
    "    iso = dt.strftime(\"%Y-%m-%dT00:00:00\")\n",
    "    return iso, year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e058ad-e36f-4067-a519-1abab7a0012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically rolls over for DD, which stretches 188 - 1887, with the entries being in chronologically order \n",
    "current_year = 1886  # start year\n",
    "standardized_dates = []\n",
    "\n",
    "for entry in diary_entries:\n",
    "    std_date, current_year = parse_diary_date_with_year(entry[\"date\"], current_year)\n",
    "    entry[\"standard_date\"] = std_date\n",
    "    standardized_dates.append(std_date)\n",
    "\n",
    "# Quick check\n",
    "for e in diary_entries[:10]:\n",
    "    print(e[\"date\"], \"â†’\", e[\"standard_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45168655-928e-4e6b-af15-6f2a3d444462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured diary saved to /Users/joenockels/douglass-kg/data/processed/HP_diary_entries.json\n"
     ]
    }
   ],
   "source": [
    "# at this point, the text entry is preserved, with ISO standard dates \n",
    "\n",
    "import json\n",
    "\n",
    "structured_path = PROJECT_ROOT / \"data\" / \"processed\" / \"HP_diary_entries.json\"\n",
    "\n",
    "with open(structured_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(diary_entries, f, indent=2)\n",
    "\n",
    "print(f\"Structured diary saved to {structured_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af77321d-d9bf-45b6-854d-f45f29cc09f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV diary saved to /Users/joenockels/douglass-kg/data/processed/HP_diary_entries.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "csv_path = PROJECT_ROOT / \"data\" / \"processed\" / \"HP_diary_entries.csv\"\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"date\", \"iso_date\", \"text\"]\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(diary_entries)\n",
    "\n",
    "print(f\"CSV diary saved to {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Douglass KG",
   "language": "python",
   "name": "douglass-kg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
